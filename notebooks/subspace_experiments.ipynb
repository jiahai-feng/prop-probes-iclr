{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47623317-a876-4d57-aab9-b577b0210792",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import dataclasses\n",
    "import yaml\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import subprocess\n",
    "\n",
    "import coref.run_manager as rm\n",
    "\n",
    "from coref import COREF_ROOT\n",
    "\n",
    "from coref.utils import slugify\n",
    "from importlib import reload\n",
    "\n",
    "import torch\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11a83c7-301c-4e5b-9e39-44b7d327ebcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "expts_root = Path(COREF_ROOT) / 'experiments'\n",
    "outputs_root = '/data/fjiahai/prop-probes-test' # choose a directory with > 20 gb space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05192ee2-e82c-42d6-9156-993fbf1fb208",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output_path(config_path, main):\n",
    "    output_path = rm.get_run_dir(\n",
    "        config_path=config_path,\n",
    "        runs_root=outputs_root,\n",
    "        experiments_root=expts_root,\n",
    "    )\n",
    "    cfg, meta_kwargs = rm.load_cfg(config_path)\n",
    "    return cfg, output_path\n",
    "\n",
    "def run_sbatch(config_path, num_devices, slurm_path):\n",
    "    slurm_cmd = ['sbatch', f'--gres=gpu:{num_devices}', slurm_path]\n",
    "    slurm_output = subprocess.run(slurm_cmd, env={**os.environ, 'CONFIG_FILE': config_path}, capture_output=True, check=True)\n",
    "    return ' '.join(slurm_cmd), slurm_output.stdout, slurm_output.stderr\n",
    "\n",
    "def get_last_output(cfg_path):\n",
    "    parent_dir = Path(rm.get_run_dir_parent(cfg_path, outputs_root, expts_root))\n",
    "    dirs = [d for d in os.listdir(parent_dir)  if os.path.isdir(parent_dir / d)]\n",
    "    success_dir = [d for d in dirs if 'done.out' in os.listdir(parent_dir / d)]\n",
    "    max_run = max(int(d) for d in dirs)\n",
    "    max_success = max(int(d) for d in success_dir)\n",
    "    if max_run != max_success:\n",
    "        print(f'Warning: latest run {max_run} of {cfg_path} is not successful. Falling back to {max_success}')\n",
    "    return parent_dir / str(max_success)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2994000-3842-44aa-83a5-eb2d3a8c4792",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Paper Subspace experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1c0186-3e49-49df-bc8a-d8253dde173b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scripts.run_hessians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46fa3d7-8ad2-4d06-bc0d-44cf95544497",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_cfg = dict(\n",
    "    num_devices=4,\n",
    "    is_hf=True,\n",
    "    hessian_mode='point',\n",
    "    name_width=1,\n",
    "    attr_width=1,\n",
    "    template=\"NameCountryTemplate\",\n",
    "    swap_dir=False,\n",
    ")\n",
    "model_cfgs = {\n",
    "    'llama': dict(\n",
    "        model=\"Llama-2-13b-chat-hf\",\n",
    "        prompt_type=\"llama_chat\"\n",
    "    ),\n",
    "    'tulu': dict(\n",
    "        model=\"tulu-2-13b\",\n",
    "        prompt_type=\"tulu_chat\"\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cb23a3-f90d-44d5-bfae-f2a7f3ee0548",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_hessian_cfg(\n",
    "    model,\n",
    "    uniform_scale,\n",
    "    interpolating_factor\n",
    "):\n",
    "    cfg = base_cfg.copy() # shallow copy\n",
    "    cfg.update(model_cfgs[model])\n",
    "    cfg['uniform_scale'] = uniform_scale\n",
    "    cfg['interpolating_factor'] = interpolating_factor\n",
    "    return scripts.run_hessians.Cfg(**cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267888b5-2119-4896-83cc-85c5d9f0602c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cfg_paths = []\n",
    "for model in model_cfgs.keys():\n",
    "    for uniform_scale in [False]:\n",
    "        for interpolating_factor in [0.5]:\n",
    "            test_path = expts_root / f'point_hessians/paper/{model}_scale_{uniform_scale}_interpolating_{interpolating_factor}.yaml'\n",
    "            all_cfg_paths.append(str(test_path))\n",
    "            build_hessian_cfg(\n",
    "                model=model,\n",
    "                uniform_scale=uniform_scale,\n",
    "                interpolating_factor=interpolating_factor\n",
    "            ).save(test_path, check=True, meta_kwargs={'_output_root': outputs_root})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0d2aa7-5d0a-4c97-a7d4-4a6cc6301c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cfg_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490d82e1-0758-49e0-9484-15f584396bc1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cmd_logs = []\n",
    "for cfg_path in all_cfg_paths[-1:]:\n",
    "    cfg, output_path = get_output_path(cfg_path, scripts.run_hessians.main)\n",
    "    slurm_cmd, slurm_out, slurm_err = run_sbatch(\n",
    "        config_path=cfg_path,\n",
    "        num_devices=cfg['num_devices'],\n",
    "        slurm_path='slurm/run_hessians.sh'\n",
    "    )\n",
    "    cmd_logs.append(f'{cfg_path}\\t{output_path}\\t{slurm_cmd}\\t{slurm_out}\\t{slurm_err}')\n",
    "for cmd in cmd_logs:\n",
    "    print(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575170ae-eb6a-4f53-8b85-60986b8238b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scripts.run_eval_form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93754e2-2b86-4e51-90cf-8206f991f1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cfg_paths = []\n",
    "\n",
    "model_cfgs = {\n",
    "    'llama': dict(\n",
    "        model=\"Llama-2-13b-chat-hf\",\n",
    "        chat_style=\"llama_chat\"\n",
    "    ),\n",
    "    'tulu': dict(\n",
    "        model=\"tulu-2-13b\",\n",
    "        chat_style=\"tulu_chat\"\n",
    "    )\n",
    "}\n",
    "def build_eval_hessian_cfg(model, form_path):\n",
    "    base_cfg = dict(\n",
    "        num_devices=2,\n",
    "        is_hf=True,\n",
    "        form_path=form_path,\n",
    "        form_type='hessian_1_1'\n",
    "    )\n",
    "    cfg = {**base_cfg, **model_cfgs[model]}\n",
    "    return scripts.run_eval_form.Cfg(**cfg)\n",
    "\n",
    "eval_cfgs = []\n",
    "    \n",
    "for model in model_cfgs.keys():\n",
    "    for uniform_scale in [False, True]:\n",
    "        for interpolating_factor in [0., 0.5, 1.]:\n",
    "            hessian_cfg = expts_root / f'point_hessians/paper/{model}_scale_{uniform_scale}_interpolating_{interpolating_factor}.yaml'\n",
    "            eval_hessian_cfg = expts_root / f'point_hessians/paper/eval_{model}_scale_{uniform_scale}_interpolating_{interpolating_factor}.yaml'\n",
    "            try:\n",
    "                hessian_dir = (get_last_output(hessian_cfg))\n",
    "            except:\n",
    "                print(f'Failed to get last output for {hessian_cfg}')\n",
    "                hessian_dir = None\n",
    "            if hessian_dir is not None:\n",
    "                form_path = str(hessian_dir / 'hessian.pt')\n",
    "                build_eval_hessian_cfg(model, form_path).save(eval_hessian_cfg, check=True, meta_kwargs={'_output_dir': str(hessian_dir / 'eval')})\n",
    "                eval_cfgs.append(eval_hessian_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc917c5a-6d08-4500-8d97-9a5b6095ce82",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_cfgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52d0aed-c1f9-49fb-875d-8c592b11617f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random baseline\n",
    "\n",
    "model_cfgs = {\n",
    "    'llama': dict(\n",
    "        model=\"Llama-2-13b-chat-hf\",\n",
    "        chat_style=\"llama_chat\"\n",
    "    ),\n",
    "    'tulu': dict(\n",
    "        model=\"tulu-2-13b\",\n",
    "        chat_style=\"tulu_chat\"\n",
    "    )\n",
    "}\n",
    "def build_random_eval_hessian_cfg(model):\n",
    "    base_cfg = dict(\n",
    "        num_devices=4,\n",
    "        is_hf=True,\n",
    "        form_path='',\n",
    "        form_type='random'\n",
    "    )\n",
    "    cfg = {**base_cfg, **model_cfgs[model]}\n",
    "    return scripts.run_eval_form.Cfg(**cfg)\n",
    "random_cfgs = []\n",
    "for model in ['llama', 'tulu']:\n",
    "    cfg_path = expts_root / f'point_hessians/paper/random_{model}.yaml'\n",
    "    build_random_eval_hessian_cfg(model).save(cfg_path, check=True, meta_kwargs={'_output_root': outputs_root})\n",
    "    random_cfgs.append(cfg_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed07a663-0450-4cd5-8738-21dc1b591822",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd_logs = []\n",
    "for cfg_path in random_cfgs  + eval_cfgs:\n",
    "    cfg, output_path = get_output_path(cfg_path, scripts.run_eval_form.main)\n",
    "    slurm_cmd, slurm_out, slurm_err = run_sbatch(\n",
    "        config_path=cfg_path,\n",
    "        num_devices=cfg['num_devices'],\n",
    "        slurm_path='slurm/run_eval_form.sh'\n",
    "    )\n",
    "    cmd_logs.append(f'{cfg_path}\\t{output_path}\\t{slurm_cmd}\\t{slurm_out}\\t{slurm_err}')\n",
    "for cmd in cmd_logs:\n",
    "    print(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d48ffd3-b087-4d19-8db3-fd0d26625a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector baseline\n",
    "import coref.vector_subspace_baseline\n",
    "\n",
    "model_cfgs = {\n",
    "    'llama': dict(\n",
    "        model=\"Llama-2-13b-chat-hf\",\n",
    "        chat_style=\"llama_chat\"\n",
    "    ),\n",
    "    'tulu': dict(\n",
    "        model=\"tulu-2-13b\",\n",
    "        chat_style=\"tulu_chat\"\n",
    "    )\n",
    "}\n",
    "def build_vector_baseline_cfg(model):\n",
    "    base_cfg = dict(\n",
    "        num_devices=2,\n",
    "        is_hf=False,\n",
    "    )\n",
    "    cfg = {**base_cfg, **model_cfgs[model]}\n",
    "    return coref.vector_subspace_baseline.Cfg(**cfg)\n",
    "baseline_cfgs = []\n",
    "for model in ['llama', 'tulu']:\n",
    "    cfg_path = expts_root / f'point_hessians/paper/baseline_{model}.yaml'\n",
    "    build_vector_baseline_cfg(model).save(cfg_path, check=True, meta_kwargs={'_output_root': outputs_root})\n",
    "    baseline_cfgs.append(cfg_path)\n",
    "baseline_cfgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69d99aa-fe9e-4c83-abbb-549bc5680c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd_logs = []\n",
    "for cfg_path in baseline_cfgs:\n",
    "    cfg, output_path = get_output_path(cfg_path, coref.vector_subspace_baseline.main)\n",
    "    slurm_cmd, slurm_out, slurm_err = run_sbatch(\n",
    "        config_path=cfg_path,\n",
    "        num_devices=cfg['num_devices'],\n",
    "        slurm_path='slurm/run_vector_subspace_baseline.sh'\n",
    "    )\n",
    "    cmd_logs.append(f'{cfg_path}\\t{output_path}\\t{slurm_cmd}\\t{slurm_out}\\t{slurm_err}')\n",
    "for cmd in cmd_logs:\n",
    "    print(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffcce2f-bf9d-464a-93f1-5b172f9ac7f1",
   "metadata": {},
   "source": [
    "## DAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5285fbc-a45d-459b-bacb-bddb3bfd8e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import coref.train_das\n",
    "model_cfgs = {\n",
    "    'llama': dict(\n",
    "        model=\"Llama-2-13b-chat-hf\",\n",
    "        chat_style=\"llama_chat\"\n",
    "    ),\n",
    "    'tulu': dict(\n",
    "        model=\"tulu-2-13b\",\n",
    "        chat_style=\"tulu_chat\"\n",
    "    )\n",
    "}\n",
    "\n",
    "def build_das_cfg(model, d_subspace):\n",
    "    base_cfg = dict(\n",
    "        num_devices=4,\n",
    "        is_hf=False,\n",
    "        d_subspace=d_subspace\n",
    "    )\n",
    "    cfg = {**base_cfg, **model_cfgs[model]}\n",
    "    return coref.train_das.Cfg(**cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c0b168-cf6b-4602-85c7-f1adc4cb1921",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dims = [1, 3, 15, 50, 250, 1000, 5120]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a9d31e-71d0-4569-be22-08ac2e526b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "das_cfgs = []\n",
    "for model in ['llama', 'tulu']:\n",
    "    for d_subspace in all_dims:\n",
    "        cfg_path = expts_root / f'das/{model}_{d_subspace}.yaml'\n",
    "        build_das_cfg(model, d_subspace).save(cfg_path, check=True, meta_kwargs={'_output_root': outputs_root})\n",
    "        das_cfgs.append(cfg_path)\n",
    "das_cfgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a2c772-a246-46d0-9537-41b94ada9eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd_logs = []\n",
    "for cfg_path in das_cfgs:\n",
    "    cfg, output_path = get_output_path(cfg_path, coref.train_das.main)\n",
    "    slurm_cmd, slurm_out, slurm_err = run_sbatch(\n",
    "        config_path=cfg_path,\n",
    "        num_devices=cfg['num_devices'],\n",
    "        slurm_path='slurm/run_das.sh'\n",
    "    )\n",
    "    cmd_logs.append(f'{cfg_path}\\t{output_path}\\t{slurm_cmd}\\t{slurm_out}\\t{slurm_err}')\n",
    "for cmd in cmd_logs:\n",
    "    print(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16335bea-b036-44a0-9f72-b906ef3ae417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval DAS\n",
    "import scripts.eval_das\n",
    "model_cfgs = {\n",
    "    'llama': dict(\n",
    "        model=\"Llama-2-13b-chat-hf\",\n",
    "        chat_style=\"llama_chat\"\n",
    "    ),\n",
    "    'tulu': dict(\n",
    "        model=\"tulu-2-13b\",\n",
    "        chat_style=\"tulu_chat\"\n",
    "    )\n",
    "}\n",
    "\n",
    "def build_eval_das_cfg(model, d_subspace, das_path):\n",
    "    base_cfg = dict(\n",
    "        num_devices=2,\n",
    "        is_hf=False,\n",
    "        das_path=das_path\n",
    "    )\n",
    "    cfg = {**base_cfg, **model_cfgs[model]}\n",
    "    return scripts.eval_das.Cfg(**cfg)\n",
    "\n",
    "eval_das_cfgs = []\n",
    "for model in ['llama', 'tulu']:\n",
    "    for d_subspace in all_dims:\n",
    "        das_cfg_path = expts_root / f'das/{model}_{d_subspace}.yaml'\n",
    "        cfg_path = expts_root / f'das/eval_{model}_{d_subspace}.yaml'\n",
    "        das_path = get_last_output(das_cfg_path)\n",
    "        print(das_path)\n",
    "        build_eval_das_cfg(model, d_subspace, str(das_path)).save(cfg_path, check=True, meta_kwargs={'_output_dir': str(os.path.join(das_path, 'eval'))})\n",
    "        eval_das_cfgs.append(cfg_path)\n",
    "eval_das_cfgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc7f81e-0768-41e0-b143-fb65b92fe7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd_logs = []\n",
    "for cfg_path in eval_das_cfgs:\n",
    "    cfg, output_path = get_output_path(cfg_path, scripts.eval_das.main)\n",
    "    slurm_cmd, slurm_out, slurm_err = run_sbatch(\n",
    "        config_path=cfg_path,\n",
    "        num_devices=cfg['num_devices'],\n",
    "        slurm_path='slurm/run_eval_das.sh'\n",
    "    )\n",
    "    cmd_logs.append(f'{cfg_path}\\t{output_path}\\t{slurm_cmd}\\t{slurm_out}\\t{slurm_err}')\n",
    "for cmd in cmd_logs:\n",
    "    print(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b48f17-a221-4340-bfd3-19bd9bd8e6b3",
   "metadata": {},
   "source": [
    "## Hessians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbefa311-2eb8-442b-8ee9-8079ab620d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scripts.run_hessians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cd70b3-608c-4dc5-b1d9-0a2c96728348",
   "metadata": {},
   "outputs": [],
   "source": [
    "hessian_paths = [\n",
    "    expts_root / 'point_hessians' / 'llama_13b_chat_widths_1_1.yaml',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95dcc4cc-a74c-44f2-826d-1a2e48f717a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cmd_logs = []\n",
    "for cfg_path in hessian_paths:\n",
    "    cfg, output_path = get_output_path(cfg_path, scripts.run_hessians.main)\n",
    "    slurm_cmd, slurm_out, slurm_err = run_sbatch(\n",
    "        config_path=cfg_path,\n",
    "        num_devices=cfg['num_devices'],\n",
    "        slurm_path='slurm/run_hessians.sh'\n",
    "    )\n",
    "    cmd_logs.append(f'{cfg_path}\\t{output_path}\\t{slurm_cmd}\\t{slurm_out}\\t{slurm_err}')\n",
    "for cmd in cmd_logs:\n",
    "    print(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e71e53-ca5b-4ef3-bf6c-1d9e2942f164",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scripts.run_eval_form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24df4649-0f44-4058-a365-a36bcc6c9ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_form_cfgs = []\n",
    "for cfg_path in hessian_paths:\n",
    "    form_type = 'hessian_1_1'\n",
    "    output_path = get_last_output(cfg_path)\n",
    "    fn = str(expts_root / 'eval_form' / f'{form_type}_{slugify(rm.get_family_name(cfg_path, outputs_root, expts_root))}.yaml')\n",
    "    scripts.run_eval_form.Cfg(\n",
    "        model=\"Llama-2-13b-chat-hf\",\n",
    "        num_devices=4,\n",
    "        is_hf=False,\n",
    "        template='NameCountryTemplate',\n",
    "        prompt_type='llama_chat',\n",
    "        form_path=str(output_path / \"hessian.pt\"),\n",
    "        form_type=form_type\n",
    "    ).save(fn)\n",
    "    eval_form_cfgs.append(fn)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a043d9-9e7f-440f-8f12-37d13f7faf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_form_cfgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0214d7-50cd-46f8-881d-871fa1aeb1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd_logs = []\n",
    "for cfg_path in eval_form_cfgs:\n",
    "    cfg, output_path = get_output_path(cfg_path, scripts.run_eval_form.main)\n",
    "    slurm_cmd, slurm_out, slurm_err = run_sbatch(\n",
    "        config_path=cfg_path,\n",
    "        num_devices=cfg['num_devices'],\n",
    "        slurm_path='slurm/run_eval_form.sh'\n",
    "    )\n",
    "    \n",
    "    cmd_logs.append(f'{cfg_path}\\t{output_path}\\t{slurm_cmd}\\t{slurm_out}\\t{slurm_err}')\n",
    "for cmd in cmd_logs:\n",
    "    print(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84d0a5c-3170-4450-a54d-ef6e622f8faf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (prop-probes-iclr)",
   "language": "python",
   "name": "prop-probes-iclr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
